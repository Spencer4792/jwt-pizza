Incident Report: JWT Pizza Service – April 8, 2025
Summary
JWT pizza service experience a large degradation of service due to an exposure attack, generating around 10000 HTTP requests to a non-existent endpoint. The high request volume caused resource exhaustion and significant latency. The incident was resolved by implementing rate limiting and path blocking in the service application.
Detection
The incident was detected during a scheduled chaos testing exercise. Monitoring systems indicated an abnormally higher number of HTTP requests to the nonexistent GET/shop/git/config endpoint, resulting in massive latency.
Impact
There was a large service impact, as there was a degradation in overall system performance due to all my AWS resources being exhausted. Additionally, there was a large user impact, as it increased the response times for legitimate user requests.
Timeline
At 9:37 there was an abnormally high number of HTTP requests detected.
At about 9:45 I identified requests targeting the non-existent GET/shop/git/config endpoint.
At 9:50 I determined the nature of the attack.
By 10:20 I implemented a rate limiting and path-specific blocking as a mitigation strategy.
At around the exact same time, I noticed that the number of HTTP requests fell significantly.
Root Cause Analysis
The root cause was a simulated security attack targeting potential Git repository exposure vulnerabilities. The attack generated thousands of requests to an endpoint that doesn’t exist, and overwhelmed the system resources. The problem was that each requests was fully processed through the middleware chain, and the middleware was making external API calls to Grafana Loki for each requests. My application lacked rate limiting to protect against high volume requests and so as a result it began to fail.
Resolution
I resolved the incident by implementing two specific features. I added rate limiting across all of the endpoints (100 requests every 15 minutes) and then a specific router handler for /shop/git paths that immediately returns a 403 forbidden response without further processing. The changes dropped the requests near instantly.
Prevention
To prevent similar things from happening in the future, I added the following changes: Rate limiting, Targeted path blocking, and improved error handling. You can read more above but in this specific instance, reducing the amount of allowed requests from any IP address significantly decreases the amount of potential load on the system.
Action Items
I implemented rate limiting for all endpoints
I added specific blocking for git exposure attempts
I reviewed and optimized the logging processes to reduce external API calls when there is a high load
I set up automated alerts for abnormal request patterns
I implemented IP blocking for the attack sources
Potential future action items include:
Adding additional monitoring for endpoint latency as an early warning system
Develop a comprehensive security testing plant to regularly test for similar vulnerabilities.
Lessons Learned
I think this incident really highlighted the importance of basic security features that you should have on a website. I never would have thought that just one source making thousands of HTTP requests could do so much damage or cost a business so much money. It’s an ingenious way of sabotage, and if somebody didn’t have the means to stop it, their business would be in jeopardy. I also think this assignment really helped me learn the importance of decent error log handling and Grafana logging. It is so important to be able to see visualizations and recognize when there is a problem, otherwise you’ll continue along and wonder why you’re losing thousands or millions to some unknown source.
![image](https://github.com/user-attachments/assets/dca29f6b-a15d-40bb-9d21-518657b9b2ea)
